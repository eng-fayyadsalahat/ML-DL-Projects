{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b68cc477",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f624738",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1590ea23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c6d811a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f49d2e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c821655a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.en import English\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac521479",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c73242d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c7d7a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pio.renderers.default = \"notebook\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a950ac",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f73b00d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/training.16m.tweet.csv\", encoding=\"ISO-8859-1\", names=[\"label\", \"id\", \"date\", \"query\", \"user\", \"tweet\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f211649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>user</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>327176</th>\n",
       "      <td>0</td>\n",
       "      <td>2009030982</td>\n",
       "      <td>Tue Jun 02 15:02:26 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>shep689</td>\n",
       "      <td>I'm always sad when i leave the gym.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396001</th>\n",
       "      <td>0</td>\n",
       "      <td>2056250825</td>\n",
       "      <td>Sat Jun 06 10:48:09 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>JessieKaitlin</td>\n",
       "      <td>About to eat a late lunch. I don't feel rested</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762315</th>\n",
       "      <td>0</td>\n",
       "      <td>2297787624</td>\n",
       "      <td>Tue Jun 23 10:52:24 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Sally_Ena</td>\n",
       "      <td>Boo I hate going to the doctor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140255</th>\n",
       "      <td>0</td>\n",
       "      <td>1880995606</td>\n",
       "      <td>Fri May 22 03:14:12 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>SorenLorensen</td>\n",
       "      <td>@belle_lulu Would do as am not at work but can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709804</th>\n",
       "      <td>0</td>\n",
       "      <td>2257728138</td>\n",
       "      <td>Sat Jun 20 14:47:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>1Sjes</td>\n",
       "      <td>Blood: the Last Vampire 2009 live-action is re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        label          id                          date     query  \\\n",
       "327176      0  2009030982  Tue Jun 02 15:02:26 PDT 2009  NO_QUERY   \n",
       "396001      0  2056250825  Sat Jun 06 10:48:09 PDT 2009  NO_QUERY   \n",
       "762315      0  2297787624  Tue Jun 23 10:52:24 PDT 2009  NO_QUERY   \n",
       "140255      0  1880995606  Fri May 22 03:14:12 PDT 2009  NO_QUERY   \n",
       "709804      0  2257728138  Sat Jun 20 14:47:53 PDT 2009  NO_QUERY   \n",
       "\n",
       "                 user                                              tweet  \n",
       "327176        shep689              I'm always sad when i leave the gym.   \n",
       "396001  JessieKaitlin    About to eat a late lunch. I don't feel rested   \n",
       "762315      Sally_Ena                    Boo I hate going to the doctor   \n",
       "140255  SorenLorensen  @belle_lulu Would do as am not at work but can...  \n",
       "709804          1Sjes  Blood: the Last Vampire 2009 live-action is re...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2aef7440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.600000e+06</td>\n",
       "      <td>1.600000e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.998818e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.000001e+00</td>\n",
       "      <td>1.935761e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.467810e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.956916e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>2.002102e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>2.177059e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>2.329206e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              label            id\n",
       "count  1.600000e+06  1.600000e+06\n",
       "mean   2.000000e+00  1.998818e+09\n",
       "std    2.000001e+00  1.935761e+08\n",
       "min    0.000000e+00  1.467810e+09\n",
       "25%    0.000000e+00  1.956916e+09\n",
       "50%    2.000000e+00  2.002102e+09\n",
       "75%    4.000000e+00  2.177059e+09\n",
       "max    4.000000e+00  2.329206e+09"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80fc2d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1600000 entries, 0 to 1599999\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count    Dtype \n",
      "---  ------  --------------    ----- \n",
      " 0   label   1600000 non-null  int64 \n",
      " 1   id      1600000 non-null  int64 \n",
      " 2   date    1600000 non-null  object\n",
      " 3   query   1600000 non-null  object\n",
      " 4   user    1600000 non-null  object\n",
      " 5   tweet   1600000 non-null  object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 73.2+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46618167",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41085fff",
   "metadata": {},
   "source": [
    "### Clean tweets: remove @username or https website from text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "684045ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweets_user(text):\n",
    "    REGx_tweet = r\"@\\S+|https?:\\S+|http?:\\S\"\n",
    "    text = re.sub(REGx_tweet, \"\", str(text).lower()).strip()\n",
    "    return \"\".join(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151e00ee",
   "metadata": {},
   "source": [
    "#### remove hashtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b031af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_hashtag(text) -> str:\n",
    "    REGx_hastag = r\"#[A-Za-z0-9_]+\"\n",
    "    text = re.sub(REGx_hastag, \" \", str(text).lower()).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905d8e65",
   "metadata": {},
   "source": [
    "### Clean punctuation: remove punctuation from text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24a3f110",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_punctuation(text):\n",
    "    clean_text = re.sub(\"[%s]\" % re.escape(string.punctuation), \"\", text)\n",
    "    return \"\".join(clean_text.strip())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20af9ba5",
   "metadata": {},
   "source": [
    "### Clean number from text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce541e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_numbers(text):\n",
    "    clean_text = re.sub('\\w*\\d\\w*', \"\", text)\n",
    "    return \"\".join(clean_text)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72e6dbe",
   "metadata": {},
   "source": [
    "### Clean stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d72643d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "stop_words.remove(\"not\")\n",
    "def clean_stopwords(text):\n",
    "    wordList = word_tokenize(text)\n",
    "    clean_text = []\n",
    "    for word in wordList:\n",
    "            if word in stop_words:\n",
    "                continue\n",
    "            else:\n",
    "                clean_text.append(word+\" \")\n",
    "    return \"\".join(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a59c6b",
   "metadata": {},
   "source": [
    "### Stemmers & Lemmatized ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86fd3906",
   "metadata": {},
   "outputs": [],
   "source": [
    "snowBallStemmer = SnowballStemmer(\"english\")\n",
    "def tweet_stemmers(text):\n",
    "    wordList = word_tokenize(text)\n",
    "    stemWords = [snowBallStemmer.stem(word+\" \") for word in wordList]\n",
    "    return \"\".join(stemWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4e77f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.95 s, sys: 1.09 s, total: 5.04 s\n",
      "Wall time: 7.49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nlp = spacy.load(\"en_core_web_lg\",disable = ['tagger','perser','ner'])\n",
    "def tweet_lemmatized(text) -> str:\n",
    "    doc = nlp(text)\n",
    "    clean_text =[str(word.lemma_) if word.lemma_ != \"-PRON-\" else str(word) for word in doc]\n",
    "    return \" \".join(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28a2695",
   "metadata": {},
   "source": [
    "### Remove emojies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2511b5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               u\"\\U0001f926-\\U0001f937\"\n",
    "                               u\"\\U00010000-\\U0010ffff\"\n",
    "                               u\"\\u2640-\\u2642\"\n",
    "                               u\"\\u2600-\\u2B55\"\n",
    "                               u\"\\u200d\"\n",
    "                               u\"\\u23cf\"\n",
    "                               u\"\\u23e9\"\n",
    "                               u\"\\u231a\"\n",
    "                               u\"\\ufe0f\"  # dingbats\n",
    "                               u\"\\u3030\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r\" \", text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef7aa90",
   "metadata": {},
   "source": [
    "#### remove arabic word "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d944dbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_arabic(text) -> str:\n",
    "    arabic_compile = re.compile(r\"[\\u0600-\\u06FF]+\",flags=re.UNICODE )\n",
    "    clean_text = arabic_compile.sub(r\" \", text)\n",
    "    clean_text = clean_text.strip()\n",
    "    clean_text = clean_text.encode(\"ascii\", \"ignore\")\n",
    "    return str(clean_text.decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548ab60b",
   "metadata": {},
   "source": [
    "### Encode Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5371c4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_text(text):\n",
    "    clean_text = text.strip()\n",
    "    clean_text = clean_text.encode(\"ascii\", \"ignore\")\n",
    "    return str(clean_text.decode())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46302286",
   "metadata": {},
   "source": [
    "## Pre Process Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "867e0756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13 s, sys: 181 ms, total: 13.2 s\n",
      "Wall time: 13.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data[\"tweet\"] = data[\"tweet\"].apply(lambda text: clean_tweets_user(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bbaad441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 12min 43s, sys: 7.63 s, total: 1h 12min 51s\n",
      "Wall time: 1h 12min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data[\"tweet\"] = data[\"tweet\"].apply(lambda text: tweet_lemmatized(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "effe9068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 12s, sys: 525 ms, total: 8min 13s\n",
      "Wall time: 8min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data[\"tweet\"] = data[\"tweet\"].apply(lambda text: tweet_stemmers(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f787499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.51 s, sys: 998 µs, total: 9.51 s\n",
      "Wall time: 9.51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data[\"tweet\"] = data[\"tweet\"].apply(lambda text: clean_punctuation(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "968f27e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 24s, sys: 18 ms, total: 3min 24s\n",
      "Wall time: 3min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data[\"tweet\"] = data[\"tweet\"].apply(lambda text: clean_stopwords(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cbe83836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.9 s, sys: 1.98 ms, total: 11.9 s\n",
      "Wall time: 11.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data[\"tweet\"] = data[\"tweet\"].apply(lambda text: clean_numbers(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3233edc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.09 s, sys: 1.01 ms, total: 1.09 s\n",
      "Wall time: 1.09 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data[\"tweet\"] = data[\"tweet\"].apply(lambda text: encode_text(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d541c4c",
   "metadata": {},
   "source": [
    "## Gensim Model\n",
    "#####   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6822a6c8",
   "metadata": {},
   "source": [
    "#### Cpu Cores count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "90c3944a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "cores = multiprocessing.cpu_count()\n",
    "cores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510b5474",
   "metadata": {},
   "source": [
    "#### TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6b4947ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 31s, sys: 640 ms, total: 2min 32s\n",
      "Wall time: 2min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tagged_data = [TaggedDocument(words=word_tokenize(_d.lower()), tags=[str(i)]) for i, _d in enumerate(data[\"tweet\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "15eda1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_data_DBOW, tagged_data_DM = train_test_split(tagged_data, test_size=0.5,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47d010b",
   "metadata": {},
   "source": [
    "#### Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be4785a",
   "metadata": {},
   "source": [
    "#### PV-DBOW model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "87e9f129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 2min 40s, sys: 8min 56s, total: 1h 11min 37s\n",
      "Wall time: 40min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_dbow = gensim.models.doc2vec.Doc2Vec(tagged_data_DBOW ,vector_size=300, negative=10, workers=(cores-1),\n",
    "                                           window=5,alpha=0.025, min_alpha=0.0001, seed=1, min_count=5,\n",
    "                                           sample=0.001, epochs=65,hs=0,dm=0, ns_exponent=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5e041163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.34 s, sys: 6.04 ms, total: 3.35 s\n",
      "Wall time: 3.35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_dbow.build_vocab(tagged_data_DBOW, update=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "02d93d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 44min 51s, sys: 18min 57s, total: 2h 3min 48s\n",
      "Wall time: 1h 12min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_dbow.train(tagged_data_DBOW, total_examples=len(tagged_data_DBOW), epochs=65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4cf59006",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dbow_file = \"models/DBOW_model/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1cb1cff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.91 s, sys: 2.01 s, total: 7.92 s\n",
      "Wall time: 9.19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_dbow.save(model_dbow_file+\"model.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6ebde7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dbow.wv.save_word2vec_format(model_dbow_file+\"model_format/model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "03c6c33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dbow.wv.save_word2vec_format(model_dbow_file+\"model_format/model.csv\", binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "758fbf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dbow.wv.save_word2vec_format(model_dbow_file+\"model_format/model.txt\", binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0347a98",
   "metadata": {},
   "source": [
    "#### DM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f78c4e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3h 42min 39s, sys: 54min 14s, total: 4h 36min 53s\n",
      "Wall time: 2h 59min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_dm = gensim.models.doc2vec.Doc2Vec(tagged_data_DM ,vector_size=300, negative=10, workers=(cores-1),\n",
    "                                         window=5,alpha=0.025, min_alpha=0.0001, seed=1, min_count=5,\n",
    "                                         sample=0.001, epochs=65,hs=0, dm=1, ns_exponent=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "47b8907d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.83 s, sys: 0 ns, total: 3.83 s\n",
      "Wall time: 3.84 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_dm.build_vocab(tagged_data_DM, update=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "196ef19a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 47min 36s, sys: 26min 38s, total: 2h 14min 15s\n",
      "Wall time: 1h 28min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_dm.train(tagged_data_DM, total_examples=len(tagged_data_DM), epochs=65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2fec3adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dm_file = \"models/DM_model/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "96dbb2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.08 s, sys: 2.41 s, total: 8.49 s\n",
      "Wall time: 9.07 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_dm.save(model_dm_file+\"model.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "328ca755",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dm.wv.save_word2vec_format(model_dm_file+\"model_format/model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4db4a994",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dm.wv.save_word2vec_format(model_dm_file+\"model_format/model.csv\", binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3d8e27da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dm.wv.save_word2vec_format(model_dm_file+\"model_format/model.txt\", binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b7186b",
   "metadata": {},
   "source": [
    "### Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df5c52b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec_dm_model = gensim.models.doc2vec.Doc2Vec.load(\"models/DM_model/model.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7671424d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('phone', 0.7605751156806946),\n",
       " ('tweet', 0.7427206039428711),\n",
       " ('twitter', 0.7217567563056946),\n",
       " ('talk', 0.6946784257888794),\n",
       " ('sorry', 0.6919742822647095),\n",
       " ('okay', 0.6901240348815918),\n",
       " ('txt', 0.683121919631958),\n",
       " ('lol', 0.6818835735321045),\n",
       " ('not', 0.6811061501502991),\n",
       " ('know', 0.6714918613433838)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2vec_dm_model.wv.most_similar(\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e0862df9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28729"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc2vec_dm_model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "52ec4316",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec_dbow_model = gensim.models.doc2vec.Doc2Vec.load(\"models/DBOW_model/model.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ae56aad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('roll', 0.2352784126996994),\n",
       " ('signage', 0.22303415834903717),\n",
       " ('undies', 0.21808171272277832),\n",
       " ('sunbed', 0.21286363899707794),\n",
       " ('shoutout', 0.19729633629322052),\n",
       " ('upp', 0.19452157616615295),\n",
       " ('precal', 0.19269666075706482),\n",
       " ('rediscover', 0.19240522384643555),\n",
       " ('linus', 0.19108791649341583),\n",
       " ('bonnet', 0.1899510771036148)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2vec_dbow_model.wv.most_similar(\"great\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e5f9787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28681"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc2vec_dbow_model.wv.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd0289e",
   "metadata": {},
   "source": [
    "### Tokenizer spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d2ef09cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = English()\n",
    "tokenizer_ng = Tokenizer(nlp.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac8567b",
   "metadata": {},
   "source": [
    "## Train data for ML "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "75924eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/data_tweet.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b0df617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tweet</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35407</th>\n",
       "      <td>30039</td>\n",
       "      <td>love tonight have interview  two great guy hav...</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.610000</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12817</th>\n",
       "      <td>7449</td>\n",
       "      <td>allahsoil stone and human be different  but to...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12109</th>\n",
       "      <td>6741</td>\n",
       "      <td>scatter  joy may we blessampkeep shine upon be...</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36571</th>\n",
       "      <td>31203</td>\n",
       "      <td>off to wembley stadium  capitalstb      readyt...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28004</th>\n",
       "      <td>22636</td>\n",
       "      <td>edc las vega we literally can not even omg    ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                              tweet  \\\n",
       "35407       30039  love tonight have interview  two great guy hav...   \n",
       "12817        7449  allahsoil stone and human be different  but to...   \n",
       "12109        6741  scatter  joy may we blessampkeep shine upon be...   \n",
       "36571       31203  off to wembley stadium  capitalstb      readyt...   \n",
       "28004       22636  edc las vega we literally can not even omg    ...   \n",
       "\n",
       "       polarity  subjectivity sentiment  \n",
       "35407  0.266667      0.610000  positive  \n",
       "12817  0.000000      0.350000  negative  \n",
       "12109  0.633333      0.566667  positive  \n",
       "36571  0.000000      0.000000   neutral  \n",
       "28004  0.000000      0.000000   neutral  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "147309ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 37330 entries, 0 to 37329\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Unnamed: 0    37330 non-null  int64  \n",
      " 1   tweet         37328 non-null  object \n",
      " 2   polarity      37330 non-null  float64\n",
      " 3   subjectivity  37330 non-null  float64\n",
      " 4   sentiment     37330 non-null  object \n",
      "dtypes: float64(2), int64(1), object(2)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1d116089",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(\"Unnamed: 0\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "460efdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"tweet\"] = train[\"tweet\"].apply(lambda text: clean_tweets_user(text))\n",
    "\n",
    "train[\"tweet\"] = train[\"tweet\"].apply(lambda text: remove_emoji(text))\n",
    "train[\"tweet\"] = train[\"tweet\"].apply(lambda text: encode_text(text))\n",
    "\n",
    "train[\"tweet\"] = train[\"tweet\"].apply(lambda text: tweet_lemmatized(text))\n",
    "train[\"tweet\"] = train[\"tweet\"].apply(lambda text: tweet_stemmers(text))\n",
    "\n",
    "train[\"tweet\"] = train[\"tweet\"].apply(lambda text: clean_numbers(text))\n",
    "train[\"tweet\"] = train[\"tweet\"].apply(lambda text: clean_punctuation(text))\n",
    "train[\"tweet\"] = train[\"tweet\"].apply(lambda text: clean_stopwords(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca3ca27",
   "metadata": {},
   "source": [
    "### Doc2Vec & ML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "457e38ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_train_data = [TaggedDocument(words=word_tokenize(_d.lower()), tags=[str(i)]) for i, _d in enumerate(train[\"tweet\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "152b9aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_data_train_DBOW, tagged_data_train_DM = train_test_split(tagged_train_data, test_size=0.5,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "19f65ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec_dbow_model.build_vocab(tagged_data_train_DBOW, update=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "57f22e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec_dm_model.build_vocab(tagged_data_train_DM, update=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "05f1d26f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'doctag_lookup': 161844200,\n",
       " 'doctag_syn0': 971065200,\n",
       " 'vocab': 14662500,\n",
       " 'vectors': 35190000,\n",
       " 'syn1neg': 35190000,\n",
       " 'total': 1217951900}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2vec_dm_model.estimate_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "497939e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'doctag_lookup': 161855200,\n",
       " 'doctag_syn0': 971131200,\n",
       " 'vocab': 14648000,\n",
       " 'vectors': 35155200,\n",
       " 'syn1neg': 35155200,\n",
       " 'total': 1217944800}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2vec_dbow_model.estimate_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8c93d913",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.test_doc2vec import ConcatenatedDoc2Vec\n",
    "new_model = ConcatenatedDoc2Vec([doc2vec_dbow_model, doc2vec_dm_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b66fd752",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "enc = OrdinalEncoder()\n",
    "train[[\"label\"]] = enc.fit_transform(train[[\"sentiment\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "37ae875f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 29864\n",
      "Test size: 7466\n"
     ]
    }
   ],
   "source": [
    "train_x, test_x = train_test_split(train, test_size=0.2, random_state=42)\n",
    "print(\"Train size:\", len(train_x))\n",
    "print(\"Test size:\", len(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "14ea8f4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29296"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc2vec_dbow_model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "86b116a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29325"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc2vec_dm_model.wv.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc403c3a",
   "metadata": {},
   "source": [
    "## Vector of word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "78824231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 19s, sys: 283 ms, total: 2min 19s\n",
      "Wall time: 2min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_a = []\n",
    "for text in train_x['tweet']:\n",
    "    train_a.append(new_model.infer_vector([str(word) for word in tokenizer_ng(text)]))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0987889f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vec = pd.DataFrame(train_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1e0d16f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.1 s, sys: 53.2 ms, total: 35.1 s\n",
      "Wall time: 35.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_a=[]\n",
    "for text in test_x['tweet']:\n",
    "    test_a.append(new_model.infer_vector([str(word) for word in tokenizer_ng(text)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f3bd2e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vec = pd.DataFrame(test_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b770f35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_x[\"label\"]\n",
    "y_test = test_x[\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115f3f9f",
   "metadata": {},
   "source": [
    "### Scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "254fde62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "std = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6a2487c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scale = std.fit_transform(train_vec)\n",
    "test_scale = std.fit_transform(test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8187486d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_norm = pd.DataFrame(train_scale) \n",
    "test_norm = pd.DataFrame(test_scale) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833ee422",
   "metadata": {},
   "source": [
    "### ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7c4f84c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e0e03ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 30min 29s, sys: 2.37 s, total: 1h 30min 32s\n",
      "Wall time: 1h 30min 35s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "82.681"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "ovr_sv = OneVsRestClassifier(SVC(kernel=\"rbf\", C=20))\n",
    "ovr_sv.fit(train_norm, y_train)\n",
    "ovr_sv_accuracy = round(ovr_sv.score(test_norm, y_test) * 100, 3)\n",
    "ovr_sv_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50739010",
   "metadata": {},
   "source": [
    "### Fine tuniing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7485e150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search\n",
    "param_grid = {\"C\": [10,20,30]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "eb6831da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 709 µs, total: 709 µs\n",
      "Wall time: 1.32 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "svc_g = OneVsRestClassifier(SVC(kernel=\"rbf\"))\n",
    "grid_svc = GridSearchCV(estimator=svc_g, param_grid=param_grid, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ef1e9f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4h 9min 35s, sys: 2.89 s, total: 4h 9min 38s\n",
      "Wall time: 4h 9min 45s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(class_weight='balanced', gamma='auto'),\n",
       "             param_grid={'C': [10, 50, 100]})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "grid_svc.fit(train_norm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "aab147ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Results from Grid Search \n",
      "\n",
      " The best estimator across ALL searched params:\n",
      " SVC(C=10, class_weight='balanced', gamma='auto')\n",
      "\n",
      " The best score across ALL searched params:\n",
      " 0.8112109034078223\n",
      "\n",
      " The best parameters across ALL searched params:\n",
      " {'C': 10}\n",
      "CPU times: user 110 µs, sys: 1e+03 µs, total: 1.11 ms\n",
      "Wall time: 697 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\" Results from Grid Search \")\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\", grid_svc.best_estimator_)\n",
    "print(\"\\n The best score across ALL searched params:\\n\", grid_svc.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\", grid_svc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248f2c04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd3817f6",
   "metadata": {},
   "source": [
    "### Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ed61931c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = joblib.load(\"models/ml_model/ml_model.sav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a53d3986",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_pre = ovr_sv.score(test_norm, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ea4ef06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 1. 2. ... 1. 2. 1.]\n",
      "CPU times: user 17min 14s, sys: 3.21 s, total: 17min 18s\n",
      "Wall time: 17min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions = cross_val_predict(ovr_sv, test_norm, y_test, cv=15)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "78f28c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.60      0.65      1740\n",
      "         1.0       0.70      0.71      0.71      1792\n",
      "         2.0       0.80      0.85      0.83      3934\n",
      "\n",
      "    accuracy                           0.76      7466\n",
      "   macro avg       0.74      0.72      0.73      7466\n",
      "weighted avg       0.76      0.76      0.76      7466\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report:\\n\", classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "02361d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[1043  214  483]\n",
      " [ 165 1276  351]\n",
      " [ 253  333 3348]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453a0883",
   "metadata": {},
   "source": [
    "### save ml model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "428792a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/ml_model/ml_model.sav']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"models/ml_model/ml_model.sav\"\n",
    "joblib.dump(ovo_sv, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9708f293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8197160460755425\n"
     ]
    }
   ],
   "source": [
    "loaded_model = joblib.load(filename)\n",
    "result = loaded_model.score(test_norm, y_test)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
